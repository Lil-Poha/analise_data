{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3689760c-41f8-4a33-9c96-3fd17803950e",
    "_uuid": "3e0ad409d438c7c68ea6a76700a1e964a357453f"
   },
   "source": [
    "# Обнаружение мошеннических транзакций\n",
    "\n",
    "Целевой признак - Class. 1 - мошенническая транзакция, 0 - нормальная.\n",
    "\n",
    "**Файл с данными: \"Fraud_data_transaction.csv\"**\n",
    "https://drive.google.com/file/d/1ZwZIZrsZzxYjSv_pO3bTqxTzhmYI6Xs8/view?usp=sharing\n",
    "\n",
    "**Цели работы:**\n",
    "\n",
    "1. Поскольку данные несбалансированы (вы должны проиллюстрировать это), то нужно создать таблицу данных с распределением 50/50 для «мошеннических» и «немошеннических» транзакций. (Алгоритм NearMiss)\n",
    "2. Определить с каким классификатором будет более высокая точность предсказаний. \n",
    "3. Создать нейронную сеть и сравнить точность с нашим лучшим классификатором.\n",
    "\n",
    "\n",
    "**План:**\n",
    "1. Прочитать данные, создать датафрейм.\n",
    "\n",
    "2. Предварительная обработка: \n",
    "a) Масштабирование и распределение; \n",
    "b) Разделение данных.\n",
    "\n",
    "3. Простое повторное использование данных (Random oversampling) и уменьшение количества данные в более представленных классах (Undersampling):\n",
    "a) Распределение и корреляция;\n",
    "b) Обнаружение аномалий;\n",
    "c) Снижение размерности и кластеризация (t-SNE);\n",
    "d) Классификаторы;\n",
    "e) Более глубокий взгляд на логистическую регрессию;\n",
    "f) Генерация синтетических данных с SMOTE;\n",
    "\n",
    "4. Оценка модели логистической регрессии на тестовом наборе.\n",
    "\n",
    "**Важно!** Данные несбалансированны. Большинство транзакций были немошенническими (99,83%). Покажите это.\n",
    "\n",
    "Если использовать эти данные без предварительной обработки в качестве основы для прогностических моделей и анализа, можно получить много ошибок, связанные с переобучением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Fraud_data_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "376ce881-463a-4a09-9ac0-c63f85577eec",
    "_kg_hide-input": true,
    "_uuid": "93031e732e5aca3a2b4984799d6bf58d76e4b52d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "03ddb929-5bc8-4af4-90cd-21dcbb57560d",
    "_kg_hide-input": true,
    "_uuid": "38bec67888aa534e9739e95ef9fac62d27a87021"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_cell_guid": "6a526b6c-8463-4f6f-92b0-e8a3a21cbb2e",
    "_kg_hide-input": true,
    "_uuid": "479a5f12d3dd68262316a17b4b7b3499e0a2cbe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, что данные несбалансированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_cell_guid": "01c007fa-0fcc-4eea-84ff-0861a2f8c533",
    "_kg_hide-input": true,
    "_uuid": "f6b96ff34855e3bf7af1f6979342b01c473e4e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мошеннических транзакций 492\n",
      "Не мошеннических транзакций 284315\n",
      "Доля не мошеннических транзакций 99.83%\n"
     ]
    }
   ],
   "source": [
    "print('Мошеннических транзакций', df[df['Class'] == 1].shape[0])\n",
    "print('Не мошеннических транзакций', df[df['Class'] == 0].shape[0])\n",
    "print(f'Доля не мошеннических транзакций {(1 - df[df['Class'] == 1].shape[0] / df[df['Class'] == 0].shape[0]) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72fdda5e-7f82-488d-a433-6157d6180bb8",
    "_uuid": "c5d6781e61c0ee84e72d26e8465bfd98ef91f3b9"
   },
   "source": [
    "## Масштабирование и распределение\n",
    "На этом этапе нужно масштабировать столбцы Time и Amount. \n",
    "Также необходимо создать подвыборку фрейма данных, чтобы иметь равное количество случаев мошенничества и немошенничества, что поможет алгоритмам лучше понять закономерности, которые определяют, является ли транзакция мошенничеством или нет.\n",
    "\n",
    "**Что такое подвыборка?**\n",
    "В этом сценарии наша подвыборка будет фреймом данных с соотношением мошеннических и немошеннических транзакций 50/50. Это означает, что ваша подвыборка будет иметь одинаковое количество мошеннических и немошеннических транзакций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_cell_guid": "cee315f2-325f-42b6-a640-736f10c272cc",
    "_kg_hide-input": true,
    "_uuid": "cfa51792bf6f8a6b318ae1bffcff4e922b1d1917"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9402/3028048997.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(amount_val, ax=ax[0], color='r')\n",
      "/tmp/ipykernel_9402/3028048997.py:10: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(time_val, ax=ax[1], color='b')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "amount_val = df['Amount'].values\n",
    "time_val = df['Time'].values\n",
    "\n",
    "sns.distplot(amount_val, ax=ax[0], color='r')\n",
    "ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
    "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "sns.distplot(time_val, ax=ax[1], color='b')\n",
    "ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
    "ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "_cell_guid": "d5d64bf0-2fbb-4096-a265-f68887bf2fde",
    "_kg_hide-input": true,
    "_uuid": "1501ec379c9b5c39c3857ba0febd0aedee9c30d5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = std_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = std_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>1.641931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254117</td>\n",
       "      <td>1.641952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>1.641974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>1.641974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514355</td>\n",
       "      <td>1.642058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V22       V23  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ...  0.277838 -0.110474   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.771679  0.909412   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.111864  1.014480   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.924384  0.012463   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.578229 -0.037501   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.800049 -0.163298   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Class  \\\n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "...          ...       ...       ...       ...       ...    ...   \n",
       "284802 -0.509348  1.436807  0.250034  0.943651  0.823731      0   \n",
       "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527      0   \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561      0   \n",
       "284805  0.123205 -0.569159  0.546668  0.108821  0.104533      0   \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649      0   \n",
       "\n",
       "        scaled_amount  scaled_time  \n",
       "0            0.244964    -1.996583  \n",
       "1           -0.342475    -1.996583  \n",
       "2            1.160686    -1.996562  \n",
       "3            0.140534    -1.996562  \n",
       "4           -0.073403    -1.996541  \n",
       "...               ...          ...  \n",
       "284802      -0.350151     1.641931  \n",
       "284803      -0.254117     1.641952  \n",
       "284804      -0.081839     1.641974  \n",
       "284805      -0.313249     1.641974  \n",
       "284806       0.514355     1.642058  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "_cell_guid": "cdb9bb1e-9fab-4fd1-a409-468ba8bc36ee",
    "_kg_hide-input": true,
    "_uuid": "a33d701247ab45d849c5e94735346a738a6c6970"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       0.244964    -1.996583 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.342475    -1.996583  1.191857  0.266151  0.166480  0.448154   \n",
       "2       1.160686    -1.996562 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       0.140534    -1.996562 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4      -0.073403    -1.996541 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a59c8c8d-a4bc-4671-aa2f-9f959c142cde",
    "_uuid": "5119c4ea9e0b9031dbc5937b56323da224985024"
   },
   "source": [
    "### Разделение данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "X = df.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "_cell_guid": "c6c962cc-6f38-4a00-bcd7-ce9d91db954c",
    "_kg_hide-input": true,
    "_uuid": "9f7b5d920703b3a3c8c0f62bc6042e4615bc8324"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.22\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shuffle \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m sss \u001b[38;5;241m=\u001b[39m \u001b[43mStratifiedKFold\u001b[49m(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m sss\u001b[38;5;241m.\u001b[39msplit(X, y):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_index)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.22, random_state=None, shuffle =False)\n",
    "\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = ...\n",
    "original_ytrain = ...\n",
    "original_ytest = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, что обучающие и тестовые данные распределены одинаково."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_label, train_counts_label = np.unique(...)\n",
    "test_unique_label, test_counts_label = ...\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "956d34b9-e562-4b70-a2f8-fbe060273a83",
    "_uuid": "cc554c4ffec656cb38d01c034f2cd338e1cb4565"
   },
   "source": [
    "## Простое повторное использование данных  (Random Under-Sampling):\n",
    "\n",
    "На этом этапе необходимо реализовать случайную недостаточную выборку, которая заключается в удалении данных для получения более сбалансированного набора данных и, таким образом, избежания переобучения моделей.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наши классы сильно перекошены, мы должны сделать их эквивалентными, чтобы иметь нормальное распределение классов. \n",
    "Перемешайте данные перед созданием подвыборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0acfc44-eb2a-4356-ad03-d0c12807acd7",
    "_kg_hide-input": true,
    "_uuid": "e3a2b89752681164f14c8273452fc66734d7f41b"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = ...\n",
    "\n",
    "normal_distributed_df = pd.concat(...)\n",
    "\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "77198464-c0f8-4694-ac0b-4b29b94d0da3",
    "_uuid": "b6818122806657e7accb8be1f4bf17086bb9b149"
   },
   "source": [
    "##  Равномерное распределение и корреляция: \n",
    "\n",
    "Теперь, когда данные сбалансированы, можно продолжить анализ и предварительную обработку данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73454100-dc69-49fd-b1b2-f72e326bca5d",
    "_kg_hide-input": true,
    "_uuid": "68b42e92df59f10fbd3ba700389796c4506af604"
   },
   "outputs": [],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_df['Class'].value_counts()/len(new_df))\n",
    "\n",
    "sns.countplot('Class', data=new_df, palette=colors)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0abc31ee-a78e-43af-822f-f06772d00c1c",
    "_uuid": "88477bac6687f110e9d64ec22837c250d85d2a2b"
   },
   "source": [
    "**Постройте матрицу корреляций для датафрейма df.**\n",
    "\n",
    "Сделайте выводы о том, каким образом признаки могут влиять на целевую переменную. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b457b10e-c17c-4cb2-9719-6d4128377c9f",
    "_kg_hide-input": true,
    "_uuid": "7bfc46c028f8602ee949de83629082633aa47b2c"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "93e56c89-185e-40d2-9ccc-29b123feb5a6",
    "_uuid": "a721282c0f44ec8030bbad6d0220091bde8cbec8"
   },
   "source": [
    "## Выявление аномалий\n",
    "Главная цель в этом разделе — удалить «экстремальные выбросы» из признаков, которые имеют высокую корреляцию с нашими классами. Это окажет положительное влияние на точность наших моделей.\n",
    "\n",
    "### Метод межквартильного размаха:\n",
    "\n",
    "Мы вычисляем его по разнице между 75-м процентилем и 25-м процентилем. Наша цель — создать порог за пределами 75-го и 25-го процентиля, чтобы в случае, если какой-либо экземпляр превысит этот порог, экземпляр был удален.\n",
    "Помимо того, что легко увидеть 25-й и 75-й процентили (оба конца квадратов), также легко увидеть экстремальные выбросы (точки за пределами нижнего и верхнего экстремума).\n",
    "\n",
    "### Компромисс удаления выбросов:\n",
    "\n",
    "Мы должны быть осторожны с тем, насколько далеко мы хотим установить порог для удаления выбросов. Мы определяем порог, умножая число (например, 1,5) на (межквартильном размахе). Чем выше этот порог, тем меньше выбросов будет обнаружено (умножение на большее число, например, 3), и чем ниже этот порог, тем больше выбросов будет обнаружено.\n",
    "\n",
    "**Компромисс:** Чем ниже порог, тем больше выбросов он удалит, однако мы хотим больше сосредоточиться на «экстремальных выбросах», а не просто на выбросах.  Вы можете поиграть с этим порогом и посмотреть, как он влияет на точность наших моделей классификации.\n",
    "\n",
    "### Резюме:\n",
    "\n",
    "**Визуализация распределений:** Сначала мы начнем с визуализации распределения признака, который мы собираемся использовать для устранения некоторых выбросов. V14 — единственный признак, который имеет гауссово распределение по сравнению с признаками V12 и V10.\n",
    "\n",
    "**Определение порога:** После того, как мы решим, какое число мы будем использовать для умножения на iqr (чем ниже, тем больше выбросов удаляется), мы продолжим определение верхнего и нижнего порогов, подставляя q25 - порог (нижний экстремальный порог) и добавляя q75 + порог (верхний экстремальный порог).\n",
    "\n",
    "**Условное отбрасывание:** Наконец, мы создаем условное отбрасывание, утверждая, что если «порог» превышен в обоих крайних значениях, то экземпляры будут удалены.\n",
    "\n",
    "Представление в виде коробчатой диаграммы: визуализируйте с помощью коробчатой диаграммы, что количество «экстремальных выбросов» было значительно сокращено.\n",
    "\n",
    "### Примечание:\n",
    "после внедрения сокращения выбросов наша точность была улучшена более чем на 3%! Некоторые выбросы могут исказить точность наших моделей, но помните, что мы должны избегать экстремальной потери информации, иначе наша модель рискует оказаться недообученной.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9c690dfa-8fed-44e5-99f5-ff4eb6f87f16",
    "_kg_hide-input": true,
    "_uuid": "b6963900379db5b0d4adf92f8c7f959164e9119f"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n",
    "\n",
    "v14_fraud_dist = new_df['V14'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#FB8861')\n",
    "ax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "v12_fraud_dist = new_df['V12'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\n",
    "ax2.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "\n",
    "v10_fraud_dist = new_df['V10'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v10_fraud_dist,ax=ax3, fit=norm, color='#C5B3F9')\n",
    "ax3.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e19fe33-f85a-4ffd-8e4a-807d0e0fb992",
    "_kg_hide-input": true,
    "_uuid": "21e43406e62a9561fba2f065ce15a8d87a1bf389"
   },
   "outputs": [],
   "source": [
    "# # -----> V14 Удаление выбросов (наивысшая отрицательная корреляция с метками)\n",
    "\n",
    "v14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\n",
    "print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
    "v14_iqr = q75 - q25\n",
    "print('iqr: {}'.format(v14_iqr))\n",
    "\n",
    "v14_cut_off = v14_iqr * 1.5\n",
    "v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\n",
    "print('Cut Off: {}'.format(v14_cut_off))\n",
    "print('V14 Lower: {}'.format(v14_lower))\n",
    "print('V14 Upper: {}'.format(v14_upper))\n",
    "\n",
    "outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\n",
    "print('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "print('V10 outliers:{}'.format(outliers))\n",
    "\n",
    "new_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)\n",
    "print('----' * 44)\n",
    "\n",
    "# -----> V12 удаление выбросов из мошеннических транзакций\n",
    "v12_fraud = ...\n",
    "q25, q75 = ...\n",
    "v12_iqr = ...\n",
    "\n",
    "v12_cut_off = v12_iqr * 1.5\n",
    "v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\n",
    "print('V12 Lower: {}'.format(v12_lower))\n",
    "print('V12 Upper: {}'.format(v12_upper))\n",
    "outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\n",
    "print('V12 outliers: {}'.format(outliers))\n",
    "print('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V12'] > v12_upper) | (new_df['V12'] < v12_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))\n",
    "print('----' * 44)\n",
    "\n",
    "\n",
    "# Удаление выбросов V10\n",
    "v10_fraud = ...\n",
    "q25, q75 = ...\n",
    "v10_iqr = ...\n",
    "\n",
    "v10_cut_off = v10_iqr * 1.5\n",
    "v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\n",
    "print('V10 Lower: {}'.format(v10_lower))\n",
    "print('V10 Upper: {}'.format(v10_upper))\n",
    "outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\n",
    "print('V10 outliers: {}'.format(outliers))\n",
    "print('Feature V10 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V10'] > v10_upper) | (new_df['V10'] < v10_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots с удаленными выбросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "66e44398-7c91-4cce-9778-4512cb838973",
    "_kg_hide-input": true,
    "_uuid": "ac80d9cfb07f1865094a8d460ae801750e93d694"
   },
   "outputs": [],
   "source": [
    "f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))\n",
    "\n",
    "colors = ['#B3F9C5', '#f9c5b3']\n",
    "# Feature V14\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df,ax=ax1, palette=colors)\n",
    "ax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\n",
    "ax1.annotate('Fewer extreme \\n outliers', xy=(0.98, -17.5), xytext=(0, -12),\n",
    "            arrowprops=dict(facecolor='black'),\n",
    "            fontsize=14)\n",
    "\n",
    "# Feature 12\n",
    "...\n",
    "\n",
    "# Feature V10\n",
    "...\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "74903f3b-dc6b-40ba-abc8-86c3df5ca46e",
    "_uuid": "0b365b10bd363c23068accc448509ced879f1670"
   },
   "source": [
    "## Снижение размерности и кластеризация. t-SNE\n",
    "\n",
    "\n",
    "Можете посмотреть видео <a href=\"https://www.youtube.com/watch?v=NEaUSP4YerM\"> StatQuest: t-SNE, Clearly Explained </a> Joshua Starmer\n",
    "\n",
    "Алгоритм **t-SNE** может довольно точно кластеризовать случаи мошенничества и не мошенничества в нашем наборе данных.\n",
    "Хотя подвыборка довольно мала, алгоритм **t-SNE** способен довольно точно обнаруживать кластеры в каждом сценарии.\n",
    "Это дает нам указание на то, что дальнейшие прогностические модели будут работать довольно хорошо при разделении случаев мошенничества и не мошенничества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f83cde6b-90d0-4e9d-ac63-fb69780431b2",
    "_kg_hide-input": true,
    "_uuid": "af3027e7df67b75c92c88d597003632e285c9bff"
   },
   "outputs": [],
   "source": [
    "X = new_df.drop('Class', axis=1)\n",
    "y = ...\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)\n",
    "t1 = time.time()\n",
    "print(\"T-SNE took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "# PCA Implementation\n",
    "t0 = time.time()\n",
    "X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)\n",
    "t1 = time.time()\n",
    "print(\"PCA took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "# TruncatedSVD\n",
    "t0 = time.time()\n",
    "X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(X.values)\n",
    "t1 = time.time()\n",
    "print(\"Truncated SVD took {:.2} s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "07015ae5-f7ac-4d64-8f41-1e4b7c9dd2ac",
    "_kg_hide-input": true,
    "_uuid": "084f2a7421c2212082491d2a90e65d65c52b434a"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24,6))\n",
    "# labels = ['No Fraud', 'Fraud']\n",
    "f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n",
    "\n",
    "\n",
    "blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\n",
    "red_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n",
    "\n",
    "\n",
    "# t-SNE scatter plot\n",
    "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
    "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
    "ax1.set_title('t-SNE', fontsize=14)\n",
    "\n",
    "ax1.grid(True)\n",
    "\n",
    "ax1.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "\n",
    "# PCA scatter plot\n",
    "...\n",
    "\n",
    "# TruncatedSVD scatter plot\n",
    "...\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb2c480a-090a-4cfb-b12e-3b74c325826c",
    "_uuid": "1b63bfd92008043cc1a336f924c835e73792f6d8"
   },
   "source": [
    "## Классификаторы UnderSampling (недостаточная выборка):\n",
    "\n",
    "\n",
    "В этом разделе необходимо обучить четыре типа классификаторов и решить какой классификатор будет более эффективен в обнаружении мошеннических транзакций. \n",
    "\n",
    "\n",
    "1. Классификатор логистической регрессии в большинстве случаев точнее, чем три других классификатора. \n",
    "2. GridSearchCV используется для определения параметров, которые дают наилучшую прогностическую оценку для классификаторов.\n",
    "3. Логистическая регрессия имеет наилучшую оценку рабочей характеристики приема (ROC), что означает, что LogisticRegression довольно точно разделяет мошеннические и не мошеннические транзакции.\n",
    "\n",
    "\n",
    "Чем больше разрыв между оценкой обучения и оценкой перекрестной проверки, тем больше вероятность того, что ваша модель переобучается (высокая дисперсия).\n",
    "Если оценка низкая как в обучающем наборе, так и в наборе для перекрестной проверки, это указывает на то, что  модель недостаточно обучена (высокое смещение)\n",
    "Логистический регрессионный классификатор показывает лучшую оценку как в обучающем наборе, так и в наборе для перекрестной проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85ce8738-7599-4b06-a722-5c0ed073599b",
    "_kg_hide-input": true,
    "_uuid": "e3751d88766a982119e522e27a9c0c647f20af85"
   },
   "outputs": [],
   "source": [
    "# Недостаточная выборка перед перекрестной проверкой (склонна к переобучению)\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные уже масштабированы, их следует разделить на обучающие и тестовые наборы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "288a65b7-8b86-44b1-973d-38dbcfe82bbb",
    "_kg_hide-input": true,
    "_uuid": "fb0a479efaa7147d6702c2c24083f1118621863f"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bccd5685-a979-451e-85b3-1cb968523540",
    "_kg_hide-input": true,
    "_uuid": "28f5178089d2d133b9e7478c1c7dc7a1f98aabee"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простые классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7810d0b9-b4e5-4b7f-909b-c127365b167c",
    "_kg_hide-input": true,
    "_uuid": "8dd4ea07fd60973fccabc2d46af28a09b0de9178"
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем перекрестную валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb37c0f6-9cfe-48b6-92d3-475d5e6767a6",
    "_kg_hide-input": true,
    "_uuid": "fe129af379caccc5428cf1836e6c96bd32e68feb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a1c35773-f4c7-4caf-9911-532784c9eae0",
    "_kg_hide-input": true,
    "_uuid": "d15b1ab16737358806e34c48dc57aa238cf0cfd2"
   },
   "outputs": [],
   "source": [
    "# Используйте GridSearchCV для поиска наилучших параметров.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\n",
    "grid_knears.fit(X_train, y_train)\n",
    "# KNears best estimator\n",
    "knears_neighbors = grid_knears.best_estimator_\n",
    "\n",
    "# Классификатор опорных векторов\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "grid_svc = GridSearchCV(SVC(), svc_params)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# SVC best estimator\n",
    "svc = grid_svc.best_estimator_\n",
    "\n",
    "# Деревья решений\n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# tree best estimator\n",
    "tree_clf = grid_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7f327bcd-335f-4e49-af07-fc4214dbcbdc",
    "_kg_hide-input": true,
    "_uuid": "1b2108bf377b924ed8a6efe580d9e162a132cd9e"
   },
   "outputs": [],
   "source": [
    "# Случай переобучения\n",
    "\n",
    "log_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "print('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "\n",
    "knears_score = ...\n",
    "print('Knears Neighbors Cross Validation Score',...)\n",
    "\n",
    "svc_score = ...\n",
    "print(...)\n",
    "\n",
    "tree_score = ...\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Undersample** с перекрестной проверкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "38e430ef-0160-47a1-9b6f-11ff62c5ecc0",
    "_kg_hide-input": true,
    "_uuid": "eeb5736b279bb8fa3804689a175394f216ec4f72"
   },
   "outputs": [],
   "source": [
    "undersample_X = df.drop('Class', axis=1)\n",
    "undersample_y = ...\n",
    "\n",
    "for train_index, test_index in sss.split(undersample_X, undersample_y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n",
    "    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n",
    "    \n",
    "undersample_Xtrain = undersample_Xtrain.values\n",
    "undersample_Xtest = ...\n",
    "undersample_ytrain = ...\n",
    "undersample_ytest = ...\n",
    "\n",
    "undersample_accuracy = []\n",
    "undersample_precision = []\n",
    "undersample_recall = []\n",
    "undersample_f1 = []\n",
    "undersample_auc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация метода **NearMiss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nearmiss, y_nearmiss = NearMiss().fit_sample(undersample_X.values, undersample_y.values)\n",
    "print('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))\n",
    "\n",
    "\n",
    "for train, test in sss.split(undersample_Xtrain, undersample_ytrain):\n",
    "    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])\n",
    "    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])\n",
    "    \n",
    "    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot LogisticRegression Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb72803c-3ea3-40cd-8ac3-399540ab7f5a",
    "_kg_hide-input": true,
    "_uuid": "a12fb2f7e104931bb78e1bd6cfc5a516c970708b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator1, estimator2, estimator3, estimator4, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(20,14), sharey=True)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    \n",
    "    # First Estimator\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#ff9124\")\n",
    "    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
    "    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
    "             label=\"Training score\")\n",
    "    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
    "             label=\"Cross-validation score\")\n",
    "    ax1.set_title(\"Logistic Regression Learning Curve\", fontsize=14)\n",
    "    ax1.set_xlabel('Training size (m)')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc=\"best\")\n",
    "    \n",
    "    # Second Estimator \n",
    "    ...\n",
    "    \n",
    "    # Third Estimator\n",
    "    ...\n",
    "    \n",
    "    # Fourth Estimator\n",
    "    ...\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5b8302aa-0207-455f-8c1a-78ff3e9b5141",
    "_kg_hide-input": true,
    "_uuid": "15b262baa0c61c288a5453031b4d7f80f5a7a5ab"
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, X_train, y_train, (0.87, 1.01), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте DataFrame со всеми оценками и именами классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "780e485a-ea64-48a0-ad97-a7516b047f32",
    "_kg_hide-input": true,
    "_uuid": "fdd59bf2c7a8e61cfb401142570643e8a29cf86b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "log_reg_pred = ...\n",
    "\n",
    "knears_pred = ...\n",
    "\n",
    "svc_pred = ...\n",
    "\n",
    "tree_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57c211c6-e88f-4634-b321-4949df08815d",
    "_kg_hide-input": true,
    "_uuid": "cb2e4715e91e36f2029ef2a5c241991ff162cd9f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))\n",
    "...\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89b0b9b6-ef82-4b69-9517-e89a79696dbb",
    "_kg_hide-input": true,
    "_uuid": "9d57aad23f3f72f3c45bf80b089a65acbce2a9ab"
   },
   "outputs": [],
   "source": [
    "log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)\n",
    "knear_fpr, knear_tpr, knear_threshold = roc_curve(y_train, knears_pred)\n",
    "svc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)\n",
    "tree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, tree_pred)\n",
    "\n",
    "\n",
    "def graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title('ROC Curve \\n Top 4 Classifiers', fontsize=18)\n",
    "    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))\n",
    "    plt.plot(knear_fpr, knear_tpr, label='KNears Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_train, knears_pred)))\n",
    "    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_train, svc_pred)))\n",
    "    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_train, tree_pred)))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([-0.01, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
    "                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
    "                )\n",
    "    plt.legend()\n",
    "    \n",
    "graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f56e6936-314c-42d4-8ea2-0cb2386ad382",
    "_uuid": "d6e62d64e9d9aa70223576a1df91a008aa6c2664"
   },
   "source": [
    "## Более детальный взгляд на логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b4eaea18-ec79-4cb2-9a92-8d70a7f593bf",
    "_kg_hide-input": true,
    "_uuid": "0daaa7137ab61d6fd88e5fcc0849acc94c693df0"
   },
   "outputs": [],
   "source": [
    "def logistic_roc_curve(log_fpr, log_tpr):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Logistic Regression ROC Curve', fontsize=16)\n",
    "    plt.plot(log_fpr, log_tpr, 'b-', linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.axis([-0.01,1,0,1])\n",
    "    \n",
    "    \n",
    "logistic_roc_curve(log_fpr, log_tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d59c7621-5adb-4339-9a04-54630f679665",
    "_uuid": "f6d54ac036fa499104d269dd52d704c71629c1b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, threshold = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "06d9e8b8-3ba5-4c1e-8480-af5a8e04f851",
    "_kg_hide-input": true,
    "_uuid": "b19df81d0a5178a260d7518f9cca804646839c01"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "y_pred = ...\n",
    "\n",
    "# Overfitting Case\n",
    "print('---' * 45)\n",
    "print('Overfitting: \\n')\n",
    "print('Recall Score: {:.2f}'.format(recall_score(y_train, y_pred)))\n",
    "print('Precision Score: {:.2f}'.format(precision_score(y_train, y_pred)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_train, y_pred)))\n",
    "print('Accuracy Score: {:.2f}'.format(accuracy_score(y_train, y_pred)))\n",
    "print('---' * 45)\n",
    "\n",
    "\n",
    "print('---' * 45)\n",
    "print('How it should be:\\n')\n",
    "print(\"Accuracy Score: {:.2f}\".format(np.mean(undersample_accuracy)))\n",
    "print(\"Precision Score: {:.2f}\".format(np.mean(undersample_precision)))\n",
    "print(\"Recall Score: {:.2f}\".format(np.mean(undersample_recall)))\n",
    "print(\"F1 Score: {:.2f}\".format(np.mean(undersample_f1)))\n",
    "print('---' * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89d88863-536f-4eea-a0cd-d2c77f407dd6",
    "_kg_hide-input": true,
    "_uuid": "f041ab92c183d2aa29569fc048ee6af4e6ee81f0"
   },
   "outputs": [],
   "source": [
    "undersample_y_score = log_reg.decision_function(original_Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f54604f-396c-421e-ae93-305ad0103591",
    "_kg_hide-input": true,
    "_uuid": "c501d9226855a510a136bbf06794c702497e5b28"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "undersample_average_precision = average_precision_score(...)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      undersample_average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2442a51e-0263-48a3-99f9-06f47bdc04f1",
    "_kg_hide-input": true,
    "_uuid": "2edd5461ff5253f12955ac02106c323f7aabe49f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(original_ytest, undersample_y_score)\n",
    "\n",
    "plt.step(recall, precision, color='#004a93', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='#48a6ff')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('UnderSampling Precision-Recall curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(\n",
    "          undersample_average_precision), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напишите выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e70e913a-173b-401b-96ee-93ddda7374c0",
    "_uuid": "d901eb00581cc890075a93d292935304e5b63355"
   },
   "source": [
    "### Метод SMOTE Over-Sampling (избыточная выборка):\n",
    "\n",
    "В отличие от случайной недостаточной выборки, SMOTE создает новые синтетические точки для достижения равного баланса классов. Это еще один вариант решения «проблем дисбаланса классов»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cc175ddc-ddd7-4087-ae1f-dd6fac664d58",
    "_kg_hide-input": true,
    "_uuid": "96f8d3f4160d65f12af4c7106739c4ad46d1e76b"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n",
    "print('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\n",
    "print('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n",
    "\n",
    "\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "f1_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "log_reg_sm = LogisticRegression()\n",
    "\n",
    "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Реализация техники SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "for train, test in sss.split(original_Xtrain, original_ytrain):\n",
    "    pipeline = imbalanced_make_pipeline(SMOTE(...), rand_log_reg)\n",
    "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
    "    best_est = rand_log_reg.best_estimator_\n",
    "    prediction = best_est.predict(original_Xtrain[test])\n",
    "    \n",
    "    accuracy_lst.append(...)\n",
    "    precision_lst.append(...)\n",
    "    recall_lst.append(...)\n",
    "    f1_lst.append(...)\n",
    "    auc_lst.append(...)\n",
    "    \n",
    "print('---' * 45)\n",
    "print('')\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
    "print('---' * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "41dd6215-2927-4de3-999a-724272aea2b6",
    "_kg_hide-input": true,
    "_uuid": "d109652d1e170d0f9938d64f29aa33d93c941cdc"
   },
   "outputs": [],
   "source": [
    "labels = ['No Fraud', 'Fraud']\n",
    "smote_prediction = best_est.predict(original_Xtest)\n",
    "print(classification_report(original_ytest, smote_prediction, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0e671f7-7ed1-4188-b9bf-e509f050b134",
    "_kg_hide-input": true,
    "_uuid": "a8dcc4bba95aed7fbc8b9e39ceeeec6902d1865c"
   },
   "outputs": [],
   "source": [
    "y_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77bed8fa-1117-4bc0-a740-bd1bd97012a4",
    "_kg_hide-input": true,
    "_uuid": "f9213b24dd2fb3eb04f9b59c3b715dcb167664b5"
   },
   "outputs": [],
   "source": [
    "average_precision = ...\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54e926f4-2a5d-4bb1-b74c-8cd79da7b6e5",
    "_kg_hide-input": true,
    "_uuid": "7be0445ac80df7ca252ec350b026d6275669aea6"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(original_ytest, y_score)\n",
    "\n",
    "plt.step(recall, precision, color='r', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='#F59B00')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('OverSampling Precision-Recall curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(\n",
    "          average_precision), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a250e819-cdd4-43f5-b0a4-eb8f232199a0",
    "_uuid": "feb07b601c9ec79be1fe96cbbadf4ac838f7f7a8"
   },
   "source": [
    "# Тестовые данные с логистической регрессией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13a7d31c-2586-4946-aaa3-60090cd5680b",
    "_kg_hide-input": true,
    "_uuid": "d0e37500506d1b942431ac5bfabedcfea30275ce"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Logistic Regression fitted using SMOTE technique\n",
    "y_pred_log_reg = ...\n",
    "\n",
    "# Other models fitted with UnderSampling\n",
    "y_pred_knear = knears_neighbors.predict(X_test)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "y_pred_tree = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для всех предсказаний постройте матрицу спутааности (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7af62152-e7e3-45c8-9a56-69467ede59a6",
    "_kg_hide-input": true,
    "_uuid": "a25f7cc327bbaeae985cb0d2f9a0c8e2c2009aa3"
   },
   "outputs": [],
   "source": [
    "# We Improve the score by 2% points approximately \n",
    "# Implement GridSearchCV and the other models.\n",
    "\n",
    "# Logistic Regression\n",
    "t0 = time.time()\n",
    "log_reg_sm = grid_log_reg.best_estimator_\n",
    "log_reg_sm.fit(Xsm_train, ysm_train)\n",
    "t1 = time.time()\n",
    "print(\"Fitting oversample data took :{} sec\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И \"classification_report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd4529fd-f38a-4dd1-8b63-467a15a2167d",
    "_kg_hide-input": true,
    "_uuid": "1380d639d3b9087ec767ed6db391fc4b8c01e765"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая оценка логистической регрессии для тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9103c5ed-df9d-4441-91dc-1104a51f06ff",
    "_kg_hide-input": true,
    "_uuid": "49c94105ad280d1ca16271daf7f9395041016c5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression with Under-Sampling\n",
    "...\n",
    "\n",
    "# Logistic Regression with SMOTE Technique (Better accuracy with SMOTE t)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте выводы**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 28120,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
