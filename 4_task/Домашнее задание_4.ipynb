{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3689760c-41f8-4a33-9c96-3fd17803950e",
    "_uuid": "3e0ad409d438c7c68ea6a76700a1e964a357453f"
   },
   "source": [
    "# Обнаружение мошеннических транзакций\n",
    "\n",
    "Целевой признак - Class. 1 - мошенническая транзакция, 0 - нормальная.\n",
    "\n",
    "**Файл с данными: \"Fraud_data_transaction.csv\"**\n",
    "https://drive.google.com/file/d/1ZwZIZrsZzxYjSv_pO3bTqxTzhmYI6Xs8/view?usp=sharing\n",
    "\n",
    "**Цели работы:**\n",
    "\n",
    "1. Поскольку данные несбалансированы (вы должны проиллюстрировать это), то нужно создать таблицу данных с распределением 50/50 для «мошеннических» и «немошеннических» транзакций. (Алгоритм NearMiss)\n",
    "2. Определить с каким классификатором будет более высокая точность предсказаний. \n",
    "3. Создать нейронную сеть и сравнить точность с нашим лучшим классификатором.\n",
    "\n",
    "\n",
    "**План:**\n",
    "1. Прочитать данные, создать датафрейм.\n",
    "\n",
    "2. Предварительная обработка: \n",
    "a) Масштабирование и распределение; \n",
    "b) Разделение данных.\n",
    "\n",
    "3. Простое повторное использование данных (Random oversampling) и уменьшение количества данные в более представленных классах (Undersampling):\n",
    "a) Распределение и корреляция;\n",
    "b) Обнаружение аномалий;\n",
    "c) Снижение размерности и кластеризация (t-SNE);\n",
    "d) Классификаторы;\n",
    "e) Более глубокий взгляд на логистическую регрессию;\n",
    "f) Генерация синтетических данных с SMOTE;\n",
    "\n",
    "4. Оценка модели логистической регрессии на тестовом наборе.\n",
    "\n",
    "**Важно!** Данные несбалансированны. Большинство транзакций были немошенническими (99,83%). Покажите это.\n",
    "\n",
    "Если использовать эти данные без предварительной обработки в качестве основы для прогностических моделей и анализа, можно получить много ошибок, связанные с переобучением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "376ce881-463a-4a09-9ac0-c63f85577eec",
    "_kg_hide-input": true,
    "_uuid": "93031e732e5aca3a2b4984799d6bf58d76e4b52d"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "03ddb929-5bc8-4af4-90cd-21dcbb57560d",
    "_kg_hide-input": true,
    "_uuid": "38bec67888aa534e9739e95ef9fac62d27a87021"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6a526b6c-8463-4f6f-92b0-e8a3a21cbb2e",
    "_kg_hide-input": true,
    "_uuid": "479a5f12d3dd68262316a17b4b7b3499e0a2cbe0"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, что данные несбалансированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01c007fa-0fcc-4eea-84ff-0861a2f8c533",
    "_kg_hide-input": true,
    "_uuid": "f6b96ff34855e3bf7af1f6979342b01c473e4e07"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72fdda5e-7f82-488d-a433-6157d6180bb8",
    "_uuid": "c5d6781e61c0ee84e72d26e8465bfd98ef91f3b9"
   },
   "source": [
    "## Масштабирование и распределение\n",
    "На этом этапе нужно масштабировать столбцы Time и Amount. \n",
    "Также необходимо создать подвыборку фрейма данных, чтобы иметь равное количество случаев мошенничества и немошенничества, что поможет алгоритмам лучше понять закономерности, которые определяют, является ли транзакция мошенничеством или нет.\n",
    "\n",
    "**Что такое подвыборка?**\n",
    "В этом сценарии наша подвыборка будет фреймом данных с соотношением мошеннических и немошеннических транзакций 50/50. Это означает, что ваша подвыборка будет иметь одинаковое количество мошеннических и немошеннических транзакций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cee315f2-325f-42b6-a640-736f10c272cc",
    "_kg_hide-input": true,
    "_uuid": "cfa51792bf6f8a6b318ae1bffcff4e922b1d1917"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "amount_val = df['Amount'].values\n",
    "time_val = df['Time'].values\n",
    "\n",
    "sns.distplot(amount_val, ax=ax[0], color='r')\n",
    "ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
    "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "sns.distplot(time_val, ax=ax[1], color='b')\n",
    "ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
    "ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d5d64bf0-2fbb-4096-a265-f68887bf2fde",
    "_kg_hide-input": true,
    "_uuid": "1501ec379c9b5c39c3857ba0febd0aedee9c30d5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# RobustScaler\n",
    "\n",
    "std_scaler = ...\n",
    "rob_scaler = ...\n",
    "\n",
    "df['scaled_amount'] = ...\n",
    "df['scaled_time'] = ...\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cdb9bb1e-9fab-4fd1-a409-468ba8bc36ee",
    "_kg_hide-input": true,
    "_uuid": "a33d701247ab45d849c5e94735346a738a6c6970"
   },
   "outputs": [],
   "source": [
    "scaled_amount = ...\n",
    "scaled_time = ...\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a59c8c8d-a4bc-4671-aa2f-9f959c142cde",
    "_uuid": "5119c4ea9e0b9031dbc5937b56323da224985024"
   },
   "source": [
    "### Разделение данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c6c962cc-6f38-4a00-bcd7-ce9d91db954c",
    "_kg_hide-input": true,
    "_uuid": "9f7b5d920703b3a3c8c0f62bc6042e4615bc8324"
   },
   "outputs": [],
   "source": [
    "X = ...\n",
    "y = ...\n",
    "\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = ...\n",
    "original_ytrain = ...\n",
    "original_ytest = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, что обучающие и тестовые данные распределены одинаково."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_label, train_counts_label = np.unique(...)\n",
    "test_unique_label, test_counts_label = ...\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "956d34b9-e562-4b70-a2f8-fbe060273a83",
    "_uuid": "cc554c4ffec656cb38d01c034f2cd338e1cb4565"
   },
   "source": [
    "## Простое повторное использование данных  (Random Under-Sampling):\n",
    "\n",
    "На этом этапе необходимо реализовать случайную недостаточную выборку, которая заключается в удалении данных для получения более сбалансированного набора данных и, таким образом, избежания переобучения моделей.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку наши классы сильно перекошены, мы должны сделать их эквивалентными, чтобы иметь нормальное распределение классов. \n",
    "Перемешайте данные перед созданием подвыборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0acfc44-eb2a-4356-ad03-d0c12807acd7",
    "_kg_hide-input": true,
    "_uuid": "e3a2b89752681164f14c8273452fc66734d7f41b"
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)\n",
    "\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = ...\n",
    "\n",
    "normal_distributed_df = pd.concat(...)\n",
    "\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "77198464-c0f8-4694-ac0b-4b29b94d0da3",
    "_uuid": "b6818122806657e7accb8be1f4bf17086bb9b149"
   },
   "source": [
    "##  Равномерное распределение и корреляция: \n",
    "\n",
    "Теперь, когда данные сбалансированы, можно продолжить анализ и предварительную обработку данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "73454100-dc69-49fd-b1b2-f72e326bca5d",
    "_kg_hide-input": true,
    "_uuid": "68b42e92df59f10fbd3ba700389796c4506af604"
   },
   "outputs": [],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_df['Class'].value_counts()/len(new_df))\n",
    "\n",
    "sns.countplot('Class', data=new_df, palette=colors)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0abc31ee-a78e-43af-822f-f06772d00c1c",
    "_uuid": "88477bac6687f110e9d64ec22837c250d85d2a2b"
   },
   "source": [
    "**Постройте матрицу корреляций для датафрейма df.**\n",
    "\n",
    "Сделайте выводы о том, каким образом признаки могут влиять на целевую переменную. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b457b10e-c17c-4cb2-9719-6d4128377c9f",
    "_kg_hide-input": true,
    "_uuid": "7bfc46c028f8602ee949de83629082633aa47b2c"
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "93e56c89-185e-40d2-9ccc-29b123feb5a6",
    "_uuid": "a721282c0f44ec8030bbad6d0220091bde8cbec8"
   },
   "source": [
    "## Выявление аномалий\n",
    "Главная цель в этом разделе — удалить «экстремальные выбросы» из признаков, которые имеют высокую корреляцию с нашими классами. Это окажет положительное влияние на точность наших моделей.\n",
    "\n",
    "### Метод межквартильного размаха:\n",
    "\n",
    "Мы вычисляем его по разнице между 75-м процентилем и 25-м процентилем. Наша цель — создать порог за пределами 75-го и 25-го процентиля, чтобы в случае, если какой-либо экземпляр превысит этот порог, экземпляр был удален.\n",
    "Помимо того, что легко увидеть 25-й и 75-й процентили (оба конца квадратов), также легко увидеть экстремальные выбросы (точки за пределами нижнего и верхнего экстремума).\n",
    "\n",
    "### Компромисс удаления выбросов:\n",
    "\n",
    "Мы должны быть осторожны с тем, насколько далеко мы хотим установить порог для удаления выбросов. Мы определяем порог, умножая число (например, 1,5) на (межквартильном размахе). Чем выше этот порог, тем меньше выбросов будет обнаружено (умножение на большее число, например, 3), и чем ниже этот порог, тем больше выбросов будет обнаружено.\n",
    "\n",
    "**Компромисс:** Чем ниже порог, тем больше выбросов он удалит, однако мы хотим больше сосредоточиться на «экстремальных выбросах», а не просто на выбросах.  Вы можете поиграть с этим порогом и посмотреть, как он влияет на точность наших моделей классификации.\n",
    "\n",
    "### Резюме:\n",
    "\n",
    "**Визуализация распределений:** Сначала мы начнем с визуализации распределения признака, который мы собираемся использовать для устранения некоторых выбросов. V14 — единственный признак, который имеет гауссово распределение по сравнению с признаками V12 и V10.\n",
    "\n",
    "**Определение порога:** После того, как мы решим, какое число мы будем использовать для умножения на iqr (чем ниже, тем больше выбросов удаляется), мы продолжим определение верхнего и нижнего порогов, подставляя q25 - порог (нижний экстремальный порог) и добавляя q75 + порог (верхний экстремальный порог).\n",
    "\n",
    "**Условное отбрасывание:** Наконец, мы создаем условное отбрасывание, утверждая, что если «порог» превышен в обоих крайних значениях, то экземпляры будут удалены.\n",
    "\n",
    "Представление в виде коробчатой диаграммы: визуализируйте с помощью коробчатой диаграммы, что количество «экстремальных выбросов» было значительно сокращено.\n",
    "\n",
    "### Примечание:\n",
    "после внедрения сокращения выбросов наша точность была улучшена более чем на 3%! Некоторые выбросы могут исказить точность наших моделей, но помните, что мы должны избегать экстремальной потери информации, иначе наша модель рискует оказаться недообученной.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9c690dfa-8fed-44e5-99f5-ff4eb6f87f16",
    "_kg_hide-input": true,
    "_uuid": "b6963900379db5b0d4adf92f8c7f959164e9119f"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n",
    "\n",
    "v14_fraud_dist = new_df['V14'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#FB8861')\n",
    "ax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "v12_fraud_dist = new_df['V12'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\n",
    "ax2.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "\n",
    "v10_fraud_dist = new_df['V10'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v10_fraud_dist,ax=ax3, fit=norm, color='#C5B3F9')\n",
    "ax3.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e19fe33-f85a-4ffd-8e4a-807d0e0fb992",
    "_kg_hide-input": true,
    "_uuid": "21e43406e62a9561fba2f065ce15a8d87a1bf389"
   },
   "outputs": [],
   "source": [
    "# # -----> V14 Удаление выбросов (наивысшая отрицательная корреляция с метками)\n",
    "\n",
    "v14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\n",
    "print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
    "v14_iqr = q75 - q25\n",
    "print('iqr: {}'.format(v14_iqr))\n",
    "\n",
    "v14_cut_off = v14_iqr * 1.5\n",
    "v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\n",
    "print('Cut Off: {}'.format(v14_cut_off))\n",
    "print('V14 Lower: {}'.format(v14_lower))\n",
    "print('V14 Upper: {}'.format(v14_upper))\n",
    "\n",
    "outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\n",
    "print('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "print('V10 outliers:{}'.format(outliers))\n",
    "\n",
    "new_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)\n",
    "print('----' * 44)\n",
    "\n",
    "# -----> V12 удаление выбросов из мошеннических транзакций\n",
    "v12_fraud = ...\n",
    "q25, q75 = ...\n",
    "v12_iqr = ...\n",
    "\n",
    "v12_cut_off = v12_iqr * 1.5\n",
    "v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\n",
    "print('V12 Lower: {}'.format(v12_lower))\n",
    "print('V12 Upper: {}'.format(v12_upper))\n",
    "outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\n",
    "print('V12 outliers: {}'.format(outliers))\n",
    "print('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V12'] > v12_upper) | (new_df['V12'] < v12_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))\n",
    "print('----' * 44)\n",
    "\n",
    "\n",
    "# Удаление выбросов V10\n",
    "v10_fraud = ...\n",
    "q25, q75 = ...\n",
    "v10_iqr = ...\n",
    "\n",
    "v10_cut_off = v10_iqr * 1.5\n",
    "v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\n",
    "print('V10 Lower: {}'.format(v10_lower))\n",
    "print('V10 Upper: {}'.format(v10_upper))\n",
    "outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\n",
    "print('V10 outliers: {}'.format(outliers))\n",
    "print('Feature V10 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V10'] > v10_upper) | (new_df['V10'] < v10_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots с удаленными выбросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "66e44398-7c91-4cce-9778-4512cb838973",
    "_kg_hide-input": true,
    "_uuid": "ac80d9cfb07f1865094a8d460ae801750e93d694"
   },
   "outputs": [],
   "source": [
    "f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))\n",
    "\n",
    "colors = ['#B3F9C5', '#f9c5b3']\n",
    "# Feature V14\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df,ax=ax1, palette=colors)\n",
    "ax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\n",
    "ax1.annotate('Fewer extreme \\n outliers', xy=(0.98, -17.5), xytext=(0, -12),\n",
    "            arrowprops=dict(facecolor='black'),\n",
    "            fontsize=14)\n",
    "\n",
    "# Feature 12\n",
    "...\n",
    "\n",
    "# Feature V10\n",
    "...\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "74903f3b-dc6b-40ba-abc8-86c3df5ca46e",
    "_uuid": "0b365b10bd363c23068accc448509ced879f1670"
   },
   "source": [
    "## Снижение размерности и кластеризация. t-SNE\n",
    "\n",
    "\n",
    "Можете посмотреть видео <a href=\"https://www.youtube.com/watch?v=NEaUSP4YerM\"> StatQuest: t-SNE, Clearly Explained </a> Joshua Starmer\n",
    "\n",
    "Алгоритм **t-SNE** может довольно точно кластеризовать случаи мошенничества и не мошенничества в нашем наборе данных.\n",
    "Хотя подвыборка довольно мала, алгоритм **t-SNE** способен довольно точно обнаруживать кластеры в каждом сценарии.\n",
    "Это дает нам указание на то, что дальнейшие прогностические модели будут работать довольно хорошо при разделении случаев мошенничества и не мошенничества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f83cde6b-90d0-4e9d-ac63-fb69780431b2",
    "_kg_hide-input": true,
    "_uuid": "af3027e7df67b75c92c88d597003632e285c9bff"
   },
   "outputs": [],
   "source": [
    "X = new_df.drop('Class', axis=1)\n",
    "y = ...\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(X.values)\n",
    "t1 = time.time()\n",
    "print(\"T-SNE took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "# PCA Implementation\n",
    "t0 = time.time()\n",
    "X_reduced_pca = PCA(n_components=2, random_state=42).fit_transform(X.values)\n",
    "t1 = time.time()\n",
    "print(\"PCA took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "# TruncatedSVD\n",
    "t0 = time.time()\n",
    "X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(X.values)\n",
    "t1 = time.time()\n",
    "print(\"Truncated SVD took {:.2} s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "07015ae5-f7ac-4d64-8f41-1e4b7c9dd2ac",
    "_kg_hide-input": true,
    "_uuid": "084f2a7421c2212082491d2a90e65d65c52b434a"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24,6))\n",
    "# labels = ['No Fraud', 'Fraud']\n",
    "f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n",
    "\n",
    "\n",
    "blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\n",
    "red_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n",
    "\n",
    "\n",
    "# t-SNE scatter plot\n",
    "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
    "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
    "ax1.set_title('t-SNE', fontsize=14)\n",
    "\n",
    "ax1.grid(True)\n",
    "\n",
    "ax1.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "\n",
    "# PCA scatter plot\n",
    "...\n",
    "\n",
    "# TruncatedSVD scatter plot\n",
    "...\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb2c480a-090a-4cfb-b12e-3b74c325826c",
    "_uuid": "1b63bfd92008043cc1a336f924c835e73792f6d8"
   },
   "source": [
    "## Классификаторы UnderSampling (недостаточная выборка):\n",
    "\n",
    "\n",
    "В этом разделе необходимо обучить четыре типа классификаторов и решить какой классификатор будет более эффективен в обнаружении мошеннических транзакций. \n",
    "\n",
    "\n",
    "1. Классификатор логистической регрессии в большинстве случаев точнее, чем три других классификатора. \n",
    "2. GridSearchCV используется для определения параметров, которые дают наилучшую прогностическую оценку для классификаторов.\n",
    "3. Логистическая регрессия имеет наилучшую оценку рабочей характеристики приема (ROC), что означает, что LogisticRegression довольно точно разделяет мошеннические и не мошеннические транзакции.\n",
    "\n",
    "\n",
    "Чем больше разрыв между оценкой обучения и оценкой перекрестной проверки, тем больше вероятность того, что ваша модель переобучается (высокая дисперсия).\n",
    "Если оценка низкая как в обучающем наборе, так и в наборе для перекрестной проверки, это указывает на то, что  модель недостаточно обучена (высокое смещение)\n",
    "Логистический регрессионный классификатор показывает лучшую оценку как в обучающем наборе, так и в наборе для перекрестной проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85ce8738-7599-4b06-a722-5c0ed073599b",
    "_kg_hide-input": true,
    "_uuid": "e3751d88766a982119e522e27a9c0c647f20af85"
   },
   "outputs": [],
   "source": [
    "# Недостаточная выборка перед перекрестной проверкой (склонна к переобучению)\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные уже масштабированы, их следует разделить на обучающие и тестовые наборы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "288a65b7-8b86-44b1-973d-38dbcfe82bbb",
    "_kg_hide-input": true,
    "_uuid": "fb0a479efaa7147d6702c2c24083f1118621863f"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bccd5685-a979-451e-85b3-1cb968523540",
    "_kg_hide-input": true,
    "_uuid": "28f5178089d2d133b9e7478c1c7dc7a1f98aabee"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простые классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7810d0b9-b4e5-4b7f-909b-c127365b167c",
    "_kg_hide-input": true,
    "_uuid": "8dd4ea07fd60973fccabc2d46af28a09b0de9178"
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем перекрестную валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb37c0f6-9cfe-48b6-92d3-475d5e6767a6",
    "_kg_hide-input": true,
    "_uuid": "fe129af379caccc5428cf1836e6c96bd32e68feb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    classifier.fit(X_train, y_train)\n",
    "    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a1c35773-f4c7-4caf-9911-532784c9eae0",
    "_kg_hide-input": true,
    "_uuid": "d15b1ab16737358806e34c48dc57aa238cf0cfd2"
   },
   "outputs": [],
   "source": [
    "# Используйте GridSearchCV для поиска наилучших параметров.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg = grid_log_reg.best_estimator_\n",
    "\n",
    "knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\n",
    "grid_knears.fit(X_train, y_train)\n",
    "# KNears best estimator\n",
    "knears_neighbors = grid_knears.best_estimator_\n",
    "\n",
    "# Классификатор опорных векторов\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "grid_svc = GridSearchCV(SVC(), svc_params)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# SVC best estimator\n",
    "svc = grid_svc.best_estimator_\n",
    "\n",
    "# Деревья решений\n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "# tree best estimator\n",
    "tree_clf = grid_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7f327bcd-335f-4e49-af07-fc4214dbcbdc",
    "_kg_hide-input": true,
    "_uuid": "1b2108bf377b924ed8a6efe580d9e162a132cd9e"
   },
   "outputs": [],
   "source": [
    "# Случай переобучения\n",
    "\n",
    "log_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\n",
    "print('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "\n",
    "knears_score = ...\n",
    "print('Knears Neighbors Cross Validation Score',...)\n",
    "\n",
    "svc_score = ...\n",
    "print(...)\n",
    "\n",
    "tree_score = ...\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Undersample** с перекрестной проверкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "38e430ef-0160-47a1-9b6f-11ff62c5ecc0",
    "_kg_hide-input": true,
    "_uuid": "eeb5736b279bb8fa3804689a175394f216ec4f72"
   },
   "outputs": [],
   "source": [
    "undersample_X = df.drop('Class', axis=1)\n",
    "undersample_y = ...\n",
    "\n",
    "for train_index, test_index in sss.split(undersample_X, undersample_y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n",
    "    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n",
    "    \n",
    "undersample_Xtrain = undersample_Xtrain.values\n",
    "undersample_Xtest = ...\n",
    "undersample_ytrain = ...\n",
    "undersample_ytest = ...\n",
    "\n",
    "undersample_accuracy = []\n",
    "undersample_precision = []\n",
    "undersample_recall = []\n",
    "undersample_f1 = []\n",
    "undersample_auc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация метода **NearMiss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nearmiss, y_nearmiss = NearMiss().fit_sample(undersample_X.values, undersample_y.values)\n",
    "print('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))\n",
    "\n",
    "\n",
    "for train, test in sss.split(undersample_Xtrain, undersample_ytrain):\n",
    "    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])\n",
    "    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])\n",
    "    \n",
    "    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot LogisticRegression Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb72803c-3ea3-40cd-8ac3-399540ab7f5a",
    "_kg_hide-input": true,
    "_uuid": "a12fb2f7e104931bb78e1bd6cfc5a516c970708b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator1, estimator2, estimator3, estimator4, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(20,14), sharey=True)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    \n",
    "    # First Estimator\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator1, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"#ff9124\")\n",
    "    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n",
    "    ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n",
    "             label=\"Training score\")\n",
    "    ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n",
    "             label=\"Cross-validation score\")\n",
    "    ax1.set_title(\"Logistic Regression Learning Curve\", fontsize=14)\n",
    "    ax1.set_xlabel('Training size (m)')\n",
    "    ax1.set_ylabel('Score')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend(loc=\"best\")\n",
    "    \n",
    "    # Second Estimator \n",
    "    ...\n",
    "    \n",
    "    # Third Estimator\n",
    "    ...\n",
    "    \n",
    "    # Fourth Estimator\n",
    "    ...\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5b8302aa-0207-455f-8c1a-78ff3e9b5141",
    "_kg_hide-input": true,
    "_uuid": "15b262baa0c61c288a5453031b4d7f80f5a7a5ab"
   },
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, X_train, y_train, (0.87, 1.01), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте DataFrame со всеми оценками и именами классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "780e485a-ea64-48a0-ad97-a7516b047f32",
    "_kg_hide-input": true,
    "_uuid": "fdd59bf2c7a8e61cfb401142570643e8a29cf86b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "\n",
    "log_reg_pred = ...\n",
    "\n",
    "knears_pred = ...\n",
    "\n",
    "svc_pred = ...\n",
    "\n",
    "tree_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57c211c6-e88f-4634-b321-4949df08815d",
    "_kg_hide-input": true,
    "_uuid": "cb2e4715e91e36f2029ef2a5c241991ff162cd9f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))\n",
    "...\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89b0b9b6-ef82-4b69-9517-e89a79696dbb",
    "_kg_hide-input": true,
    "_uuid": "9d57aad23f3f72f3c45bf80b089a65acbce2a9ab"
   },
   "outputs": [],
   "source": [
    "log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)\n",
    "knear_fpr, knear_tpr, knear_threshold = roc_curve(y_train, knears_pred)\n",
    "svc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)\n",
    "tree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, tree_pred)\n",
    "\n",
    "\n",
    "def graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.title('ROC Curve \\n Top 4 Classifiers', fontsize=18)\n",
    "    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))\n",
    "    plt.plot(knear_fpr, knear_tpr, label='KNears Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_train, knears_pred)))\n",
    "    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_train, svc_pred)))\n",
    "    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_train, tree_pred)))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([-0.01, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
    "                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
    "                )\n",
    "    plt.legend()\n",
    "    \n",
    "graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f56e6936-314c-42d4-8ea2-0cb2386ad382",
    "_uuid": "d6e62d64e9d9aa70223576a1df91a008aa6c2664"
   },
   "source": [
    "## Более детальный взгляд на логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b4eaea18-ec79-4cb2-9a92-8d70a7f593bf",
    "_kg_hide-input": true,
    "_uuid": "0daaa7137ab61d6fd88e5fcc0849acc94c693df0"
   },
   "outputs": [],
   "source": [
    "def logistic_roc_curve(log_fpr, log_tpr):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.title('Logistic Regression ROC Curve', fontsize=16)\n",
    "    plt.plot(log_fpr, log_tpr, 'b-', linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.axis([-0.01,1,0,1])\n",
    "    \n",
    "    \n",
    "logistic_roc_curve(log_fpr, log_tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d59c7621-5adb-4339-9a04-54630f679665",
    "_uuid": "f6d54ac036fa499104d269dd52d704c71629c1b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, threshold = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "06d9e8b8-3ba5-4c1e-8480-af5a8e04f851",
    "_kg_hide-input": true,
    "_uuid": "b19df81d0a5178a260d7518f9cca804646839c01"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "y_pred = ...\n",
    "\n",
    "# Overfitting Case\n",
    "print('---' * 45)\n",
    "print('Overfitting: \\n')\n",
    "print('Recall Score: {:.2f}'.format(recall_score(y_train, y_pred)))\n",
    "print('Precision Score: {:.2f}'.format(precision_score(y_train, y_pred)))\n",
    "print('F1 Score: {:.2f}'.format(f1_score(y_train, y_pred)))\n",
    "print('Accuracy Score: {:.2f}'.format(accuracy_score(y_train, y_pred)))\n",
    "print('---' * 45)\n",
    "\n",
    "\n",
    "print('---' * 45)\n",
    "print('How it should be:\\n')\n",
    "print(\"Accuracy Score: {:.2f}\".format(np.mean(undersample_accuracy)))\n",
    "print(\"Precision Score: {:.2f}\".format(np.mean(undersample_precision)))\n",
    "print(\"Recall Score: {:.2f}\".format(np.mean(undersample_recall)))\n",
    "print(\"F1 Score: {:.2f}\".format(np.mean(undersample_f1)))\n",
    "print('---' * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "89d88863-536f-4eea-a0cd-d2c77f407dd6",
    "_kg_hide-input": true,
    "_uuid": "f041ab92c183d2aa29569fc048ee6af4e6ee81f0"
   },
   "outputs": [],
   "source": [
    "undersample_y_score = log_reg.decision_function(original_Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f54604f-396c-421e-ae93-305ad0103591",
    "_kg_hide-input": true,
    "_uuid": "c501d9226855a510a136bbf06794c702497e5b28"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "undersample_average_precision = average_precision_score(...)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      undersample_average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2442a51e-0263-48a3-99f9-06f47bdc04f1",
    "_kg_hide-input": true,
    "_uuid": "2edd5461ff5253f12955ac02106c323f7aabe49f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(original_ytest, undersample_y_score)\n",
    "\n",
    "plt.step(recall, precision, color='#004a93', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='#48a6ff')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('UnderSampling Precision-Recall curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(\n",
    "          undersample_average_precision), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напишите выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e70e913a-173b-401b-96ee-93ddda7374c0",
    "_uuid": "d901eb00581cc890075a93d292935304e5b63355"
   },
   "source": [
    "### Метод SMOTE Over-Sampling (избыточная выборка):\n",
    "\n",
    "В отличие от случайной недостаточной выборки, SMOTE создает новые синтетические точки для достижения равного баланса классов. Это еще один вариант решения «проблем дисбаланса классов»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cc175ddc-ddd7-4087-ae1f-dd6fac664d58",
    "_kg_hide-input": true,
    "_uuid": "96f8d3f4160d65f12af4c7106739c4ad46d1e76b"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "\n",
    "print('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\n",
    "print('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n",
    "\n",
    "\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "f1_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "log_reg_sm = LogisticRegression()\n",
    "\n",
    "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Реализация техники SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "for train, test in sss.split(original_Xtrain, original_ytrain):\n",
    "    pipeline = imbalanced_make_pipeline(SMOTE(...), rand_log_reg)\n",
    "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
    "    best_est = rand_log_reg.best_estimator_\n",
    "    prediction = best_est.predict(original_Xtrain[test])\n",
    "    \n",
    "    accuracy_lst.append(...)\n",
    "    precision_lst.append(...)\n",
    "    recall_lst.append(...)\n",
    "    f1_lst.append(...)\n",
    "    auc_lst.append(...)\n",
    "    \n",
    "print('---' * 45)\n",
    "print('')\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
    "print('---' * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "41dd6215-2927-4de3-999a-724272aea2b6",
    "_kg_hide-input": true,
    "_uuid": "d109652d1e170d0f9938d64f29aa33d93c941cdc"
   },
   "outputs": [],
   "source": [
    "labels = ['No Fraud', 'Fraud']\n",
    "smote_prediction = best_est.predict(original_Xtest)\n",
    "print(classification_report(original_ytest, smote_prediction, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0e671f7-7ed1-4188-b9bf-e509f050b134",
    "_kg_hide-input": true,
    "_uuid": "a8dcc4bba95aed7fbc8b9e39ceeeec6902d1865c"
   },
   "outputs": [],
   "source": [
    "y_score = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "77bed8fa-1117-4bc0-a740-bd1bd97012a4",
    "_kg_hide-input": true,
    "_uuid": "f9213b24dd2fb3eb04f9b59c3b715dcb167664b5"
   },
   "outputs": [],
   "source": [
    "average_precision = ...\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54e926f4-2a5d-4bb1-b74c-8cd79da7b6e5",
    "_kg_hide-input": true,
    "_uuid": "7be0445ac80df7ca252ec350b026d6275669aea6"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(original_ytest, y_score)\n",
    "\n",
    "plt.step(recall, precision, color='r', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='#F59B00')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('OverSampling Precision-Recall curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(\n",
    "          average_precision), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a250e819-cdd4-43f5-b0a4-eb8f232199a0",
    "_uuid": "feb07b601c9ec79be1fe96cbbadf4ac838f7f7a8"
   },
   "source": [
    "# Тестовые данные с логистической регрессией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13a7d31c-2586-4946-aaa3-60090cd5680b",
    "_kg_hide-input": true,
    "_uuid": "d0e37500506d1b942431ac5bfabedcfea30275ce"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Logistic Regression fitted using SMOTE technique\n",
    "y_pred_log_reg = ...\n",
    "\n",
    "# Other models fitted with UnderSampling\n",
    "y_pred_knear = knears_neighbors.predict(X_test)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "y_pred_tree = tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для всех предсказаний постройте матрицу спутааности (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7af62152-e7e3-45c8-9a56-69467ede59a6",
    "_kg_hide-input": true,
    "_uuid": "a25f7cc327bbaeae985cb0d2f9a0c8e2c2009aa3"
   },
   "outputs": [],
   "source": [
    "# We Improve the score by 2% points approximately \n",
    "# Implement GridSearchCV and the other models.\n",
    "\n",
    "# Logistic Regression\n",
    "t0 = time.time()\n",
    "log_reg_sm = grid_log_reg.best_estimator_\n",
    "log_reg_sm.fit(Xsm_train, ysm_train)\n",
    "t1 = time.time()\n",
    "print(\"Fitting oversample data took :{} sec\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И \"classification_report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd4529fd-f38a-4dd1-8b63-467a15a2167d",
    "_kg_hide-input": true,
    "_uuid": "1380d639d3b9087ec767ed6db391fc4b8c01e765"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая оценка логистической регрессии для тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9103c5ed-df9d-4441-91dc-1104a51f06ff",
    "_kg_hide-input": true,
    "_uuid": "49c94105ad280d1ca16271daf7f9395041016c5c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression with Under-Sampling\n",
    "...\n",
    "\n",
    "# Logistic Regression with SMOTE Technique (Better accuracy with SMOTE t)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте выводы**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 28120,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
